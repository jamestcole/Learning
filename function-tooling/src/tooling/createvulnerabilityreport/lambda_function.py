from collections import Counter
from itertools import batched
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Iterator
from datetime import date

import boto3
import pandas as pd
from kubernetes import client
from pylibrarycore.datatypes.lambda_context import LambdaContext
from pylibrarycore.logging.logger_utils import setup_logging, with_lambda_logging_context, get_logger

from tooling.createvulnerabilityreport.check_aws_access import check_aws_access
from tooling.createvulnerabilityreport.send_slack_notification import send_slack_notification

setup_logging()
logger = get_logger(__name__)
SEVERITIES = ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNTRIAGED"]
SEVERITY_ICONS = [":zap:", ":red_circle:", ":large_orange_circle:", ":large_yellow_circle:", ":white-circle:"]
SEVERITY_ICON_MAPPING = dict(zip(SEVERITIES, SEVERITY_ICONS))

MAX_PARALLELISM = 20
region_aliases = {
    "eu-west-1": "ire",
    "eu-west-2": "lon"
}


@with_lambda_logging_context
def lambda_handler(event: dict[str, Any], _1: LambdaContext) -> None:
    try:
        setup(event)
        check_aws_access(event)
        print_vulnerability_details(event)
    except Exception as error:
        logger.exception("Failed")
        raise error


def fail_with(message: str) -> None:
    print(message)
    exit(1)


# todo validate args
def setup(event: dict[str, Any]) -> None:
    check_aws_access(event)


def print_vulnerability_details(event: dict[str, Any]) -> None:
    image_by_hash = get_cluster_image_details(event["cluster"])
    if not image_by_hash:
        fail_with(f'No images found in {event["region"]} for cluster {event["cluster"]}')
    vulnerabilities = get_vulnerabilities_for_images(image_by_hash, event["status"], event["severities"])
    if not vulnerabilities:
        fail_with(f'No {event["status"]} vulnerabilities found in {event["region"]} for cluster {event["cluster"]}')
    data = sort_detail(vulnerabilities)
    url = write_output(data, event)
    summary_text = count_vulnerabilities(event, vulnerabilities)
    send_slack_notification(event, url, summary_text)


def count_vulnerabilities(event: dict[str, Any], vulnerabilities: list[Any]) -> str:
    severity_count = Counter(vuln["Severity"] for vuln in vulnerabilities)
    return ", ".join(
        f"{SEVERITY_ICON_MAPPING.get(severity, ':white_circle:')} {severity_count.get(severity, 0)} {severity}" for
        severity in event['severities'])


def get_cluster_image_details(cluster: str) -> dict[str, dict[str, Any]]:
    start_time = time.time()
    clusters = [cluster] if cluster else get_eks_clusters()
    all_images: dict[Any, set[Any]] = {}
    for cluster in clusters:
        images = get_images_from_cluster(cluster)
        for image, cluster_set in images.items():
            all_images[image] = all_images.get(image, set()) | cluster_set

    ecr_images_with_hashes = get_ecr_images_with_hashes()
    image_hashes = [parse_image(image) | {"image": image, "Clusters": clusters,
                                          "ImageHash": ecr_images_with_hashes.get(image, "N/A")} for
                    image, clusters in all_images.items()]
    image_by_hash = {item["ImageHash"]: item for item in image_hashes}
    end_time = time.time()

    print(f'Retrieved {len(image_hashes)} images in {end_time - start_time:.2f} seconds.')
    return image_by_hash


def get_vulnerabilities_for_images(image_by_hash: dict[str, dict[str, Any]], statuses: list[str],
                                   severities: list[str]) -> list[Any]:
    start_time = time.time()
    inspector_client = boto3.client("inspector2")
    vulnerabilities = []
    paginator = inspector_client.get_paginator("list_findings")
    hash_batches = list(batched(image_by_hash.keys(), 10))

    def process_batch(batch: Iterator[tuple[Any, Any]]) -> list[Any]:
        local_vulnerabilities = []
        filter_criteria = {
            'ecrImageHash': [{'comparison': 'EQUALS', 'value': image_hash} for image_hash in batch],
            'findingStatus': [{'comparison': 'EQUALS', 'value': status} for status in statuses],
            'severity': [{'comparison': 'EQUALS', 'value': severity} for severity in severities]
        }
        for page in paginator.paginate(filterCriteria=filter_criteria):
            if "findings" in page:
                for finding in page["findings"]:
                    image_hash = finding.get("resources", [{}])[0].get('details', {}).get("awsEcrContainerImage",
                                                                                          {}).get("imageHash")
                    if image_hash:
                        image = image_by_hash[image_hash]
                        for cluster in image.get('Clusters', []):
                            local_vulnerabilities.append({
                                "Registry": image["Registry"],
                                "Repository": image["Repository"],
                                "Tag": image["Tag"],
                                "ImageHash": image["ImageHash"],
                                "CVE": finding["title"],
                                "Score": finding.get("inspectorScore", "?"),
                                "Fixable": finding["fixAvailable"],
                                "Exploitable": finding["exploitAvailable"],
                                "EPSS": finding.get("epss", {}).get("score", "?"),
                                "Severity": finding["severity"],
                                "Status": finding["status"],
                                "FirstObservedAt": finding["firstObservedAt"],
                                "Cluster": cluster
                            })
        return local_vulnerabilities

    with ThreadPoolExecutor(max_workers=MAX_PARALLELISM) as executor:
        results = executor.map(process_batch, hash_batches)

    for result in results:
        vulnerabilities.extend(result)

    end_time = time.time()
    print(f'Retrieved {len(vulnerabilities)} vulnerabilities in {end_time - start_time:.2f} seconds.')
    return vulnerabilities


def parse_image(image: str) -> dict[str, str]:
    if ":" in image:
        image_reference, tag = image.rsplit(":", 1)
    else:
        image_reference, tag = image, "latest"

    if "/" in image_reference:
        registry, repository = image_reference.split("/", 1)
    else:
        registry, repository = "unknown", image_reference

    return {
        "Registry": registry,
        "Repository": repository,
        "Tag": tag
    }


def sort_detail(vulnerabilities: list[Any]) -> Any:
    df = pd.DataFrame(vulnerabilities)
    df["Severity"] = pd.Categorical(df["Severity"],
                                    categories=SEVERITIES,
                                    ordered=True)

    df = df[["CVE", "Status", "Severity", "Score", "EPSS", "Exploitable",
             "Fixable", "Cluster", "Repository", "Tag", "ImageHash", "FirstObservedAt"]]
    df.sort_values(by=["Severity"], ascending=[True], inplace=True)
    return df


def write_output(data: Any, event: dict[str, Any]) -> str:
    output_data = data.to_csv(index=False, quoting=1)
    s3_client = boto3.client('s3')
    key = get_s3_filename(event)
    s3_client.put_object(Bucket='rbs.mobile.ire.nonprod.inspector', Key=key, Body=output_data)
    return (f'https://{event['region']}.console.aws.amazon.com/s3/object/rbs.mobile.ire.nonprod.inspector'
            f'?region={event['region']}&bucketType=general&prefix={key}')


def get_s3_filename(event: dict[str, Any]) -> str:
    cluster = event['cluster']
    region = region_aliases[event['region']]
    statuses = '_'.join(event['status'])
    severities = '_'.join(event['severities'])
    return date.today().strftime(f"%Y/%m/%d/cve_report_detail_{cluster}_{region}_{statuses}_{severities}_%Y_%m_%d.csv")


def get_eks_clusters() -> list[str]:
    eks_client = boto3.client("eks")
    clusters = []

    response = eks_client.list_clusters()
    clusters.extend(response["clusters"])

    while "nextToken" in response:
        response = eks_client.list_clusters(nextToken=response["nextToken"])
        clusters.extend(response["clusters"])

    return clusters


def get_images_from_cluster(cluster_name: str) -> dict[str, set[str]]:
    v1 = client.CoreV1Api()
    images: dict[str, set[str]] = {}

    try:
        namespaces = v1.list_namespace().items
        namespace_names = [ns.metadata.name for ns in namespaces if ns.metadata is not None]

        def process_namespace(namespace: str) -> dict[Any, Any]:
            local_images: dict[Any, Any] = {}
            pods = v1.list_namespaced_pod(namespace=namespace)
            for pod in pods.items:
                if pod.spec is not None:
                    for container in pod.spec.containers:
                        local_images[container.image] = local_images.get(container.image, set())
                        local_images[container.image].add(cluster_name)
            return local_images

        with ThreadPoolExecutor(max_workers=MAX_PARALLELISM) as executor:
            namespace_images = executor.map(process_namespace, namespace_names)

        for ns_images in namespace_images:
            for image, cluster_set in ns_images.items():
                images[image] = images.get(image, set()) | cluster_set

    except Exception as e:
        print(f'Error retrieving namespaces from cluster {cluster_name}: {e}')

    return images


def get_ecr_images_with_hashes() -> dict[Any, Any]:
    ecr_client = boto3.client("ecr")
    images_with_hashes = {}

    paginator = ecr_client.get_paginator("describe_repositories")
    repositories = []

    for page in paginator.paginate():
        repositories.extend(page["repositories"])

    def process_repository(repo: dict[Any, Any]) -> dict[Any, Any]:
        local_images = {}
        try:
            image_paginator = ecr_client.get_paginator("list_images")
            for image_page in image_paginator.paginate(repositoryName=repo["repositoryName"]):
                for img in image_page.get("imageIds", []):
                    image_tag = img.get("imageTag", "latest")
                    if "imageDigest" in img:
                        image_digest = img["imageDigest"]
                        local_images[f'{repo["repositoryUri"]}:{image_tag}'] = image_digest
        except Exception as e:
            print(f'Error retrieving images for repository {repo["repositoryName"]}: {e}')
        return local_images

    with ThreadPoolExecutor(max_workers=MAX_PARALLELISM) as executor:
        repository_images = executor.map(process_repository, repositories)
    for repo_images in repository_images:
        images_with_hashes.update(repo_images)

    return images_with_hashes
